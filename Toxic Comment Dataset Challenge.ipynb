{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Dataset Challenge\n",
    "\n",
    "Here I would be working on the Google Jigsaw Toxic Comment Classification challenge on Kaggle. Here is the link to the competition in Kaggle https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge. Some of the methods and practices that I would be using in this notebook are inspired by \"Jeremy Howard\" in his Kaggle notebook https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline and \"Bongo\" in https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras\n",
    "\n",
    "## Question or problem definition.\n",
    "\n",
    "Discussing things you care about can be difficult. The threat of abuse and harassment online means that many people stop expressing themselves and give up on seeking different opinions. Platforms struggle to effectively facilitate conversations, leading many communities to limit or completely shut down user comments.\n",
    "\n",
    "You are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:\n",
    "- toxic\n",
    "- severe_toxic\n",
    "- obscene\n",
    "- threat\n",
    "- insult\n",
    "- identity_hate\n",
    "\n",
    "The challenge requires us to create a model which predicts a probability of each type of toxicity for each comment. In this notebook I intend to try out a Naive-Bayes model using a bag-of-words model built using Tf-Idf vectorizer and to try out Keras to build a simple Keras model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire training and testing data\n",
    "\n",
    "Here we obtain the data from the dataset csv file by reading it into our Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('toxic/train.csv')\n",
    "test = pd.read_csv('toxic/test.csv')\n",
    "subm = pd.read_csv('toxic/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12    0.5           0.5      0.5     0.5     0.5   \n",
       "1  0000247867823ef7    0.5           0.5      0.5     0.5     0.5   \n",
       "2  00013b17ad220c46    0.5           0.5      0.5     0.5     0.5   \n",
       "3  00017563c3f7919a    0.5           0.5      0.5     0.5     0.5   \n",
       "4  00017695ad8997eb    0.5           0.5      0.5     0.5     0.5   \n",
       "\n",
       "   identity_hate  \n",
       "0            0.5  \n",
       "1            0.5  \n",
       "2            0.5  \n",
       "3            0.5  \n",
       "4            0.5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this command we should be able to find out if there are any null values in train or test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(id               False\n",
       " comment_text     False\n",
       " toxic            False\n",
       " severe_toxic     False\n",
       " obscene          False\n",
       " threat           False\n",
       " insult           False\n",
       " identity_hate    False\n",
       " dtype: bool, id              False\n",
       " comment_text    False\n",
       " dtype: bool)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any(), test.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle, prepare, cleanse the data\n",
    "\n",
    "Let us go ahead and get the comment text from the dataset and try to build a feature from the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_text = train['comment_text']\n",
    "comment_text[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us analyze the comments text and see how they look in shape and size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394.0732213246768, 590.7202819048923, 5000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = train.comment_text.str.len()\n",
    "lengths.mean(), lengths.std(), lengths.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the distribution of number of comments with the length of the comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1f805320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can feature engineer another column 'None' to classify comments that are within the guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.898321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate           none  \n",
       "count  159571.000000  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805       0.898321  \n",
       "std         0.216627       0.093420       0.302226  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       1.000000  \n",
       "50%         0.000000       0.000000       1.000000  \n",
       "75%         0.000000       0.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(train.columns)\n",
    "cols.remove('id')\n",
    "cols.remove('comment_text')\n",
    "train['none'] = 1-train[cols].max(axis=1)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us see how big our training and test set are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 153164)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to find out the classification for each comment and also wrangle the comments from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = train[cols].values\n",
    "comments_train = train[\"comment_text\"]\n",
    "comments_test = test[\"comment_text\"]\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze, identify patterns, and explore the data.\n",
    "\n",
    "Here we would be using a tf-idf bag-of-words model to model the characters in the dataset. A TF-IDF vectorizer uses the term frequency and inverse document frequency to calculate the important of a term to the comment and overall importance. Here's a link to learn more about tf-idf http://www.tfidf.com/.\n",
    "\n",
    "In order to extract the words from the comment and disregard all the punctuation in the comment, we would use regex and the string module in order to build the feature. \n",
    "\n",
    "The TfIdf vectorizer takes a comment and builds a feature for the words in the comment from the words that occur in the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "re_tok = re.compile(f'([{string.punctuation}“”£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we would be using the Tfidf vectorizer to build our bag-of-words model. \n",
    "\n",
    "- ngram_range \n",
    "    - creates ngrams(weighted sequences of text of length (1,3). \n",
    "- Min_df and max_df. \n",
    "    - For the values to make sense heres the formula for inverse document frequency\n",
    "        - IDF(t) = log_e(Total number of documents / Number of documents with term t in it). \n",
    "    - The log_e function should give a clue unto the value of the parameters min_df and max_df cut off idf values that are going to be larger than 3 and less than 0.9 in order to remove words that are:\n",
    "        - insignificant in occurence\n",
    "        - stopwords (words like 'at', 'a', 'in') that repeat too many items to be statistically significant\n",
    "\n",
    "More information on the TF-IDF vectorizer is available at  http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = train.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,3), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "X_train = vec.fit_transform(train[\"comment_text\"])\n",
    "X_test = vec.transform(test[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here let us define a probability function for a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob(y_i, y, x):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, predict and solve the problem.\n",
    "\n",
    "Here we would be using LogisticRegression models to create binary classifiers for each feature that we have. \n",
    "C in the Regression models are inverse of regularization strength, smaller values specify stronger regularization, default value is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(y):\n",
    "    y = y.values\n",
    "    r = np.log(prob(1,y, X_train) / prob(0,y, X_train))\n",
    "    m = LogisticRegression(C=4)\n",
    "    x_nb = X_train.multiply(r)\n",
    "    return m.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us initialize a empty array to store our predictions now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((len(test), len(cols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are looking to train a binary LogisticRegression model to classify for each type of label and use that to predict the probabilities for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n",
      "fit severe_toxic\n",
      "fit obscene\n",
      "fit threat\n",
      "fit insult\n",
      "fit identity_hate\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(cols):\n",
    "    print('fit', col)\n",
    "    m,r = get_model(train[col])\n",
    "    preds[:,i] = m.predict_proba(X_test.multiply(r))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_id = pd.DataFrame({'id': subm[\"id\"]})\n",
    "submission = pd.concat([subm_id, pd.DataFrame(preds, columns = cols)], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
